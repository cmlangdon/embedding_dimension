{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "### Figure\n",
    "#### Reduced model "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5b6f03c9ba79b2cf"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Find a clustered basis for neural activity. Cluster hyperplanes, weight each entry in Q by magnitude of hyperplane.\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c47d854ddf1454fa"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/cl1704/PycharmProjects/embedding_dimension/RNN\n"
     ]
    }
   ],
   "source": [
    "cd /Users/cl1704/PycharmProjects/embedding_dimension/RNN"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-14T13:45:37.907516Z",
     "start_time": "2025-05-14T13:45:37.903296Z"
    }
   },
   "id": "416c32ec1544289c",
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-14T13:45:38.628023Z",
     "start_time": "2025-05-14T13:45:38.625081Z"
    }
   },
   "id": "c8db4a8e489297c8",
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2afc\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "from Experiment_1.TwoAFCTask import generate_trials\n",
    "#from Experiment_5.SiegelMillerTask import generate_trials\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import gridspec\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "\n",
    "import seaborn as sns\n",
    "from Experiment_1.net import *\n",
    "import os\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "import scipy.optimize as opt\n",
    "import math\n",
    "#from psychometrics import *\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.decomposition import PCA\n",
    "import networkx as nx\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "plt.rcParams[\"axes.grid\"] = False\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "matplotlib.rcParams['axes.linewidth'] = .75"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-14T13:45:40.084150Z",
     "start_time": "2025-05-14T13:45:38.844561Z"
    }
   },
   "id": "24bd05cd4c1e6379",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Load data\n",
    "df_list = []\n",
    "for filename in os.listdir('Experiment_1/Results_1'):\n",
    "    f = os.path.join('Experiment_1/Results_1', filename)\n",
    "    if os.path.isfile(f):\n",
    "        df_list.append(pd.read_pickle(f))\n",
    "original_df = pd.concat(df_list, ignore_index=True)\n",
    "#original_df = original_df[original_df.mse_z < .035]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-14T15:00:16.976861Z",
     "start_time": "2025-05-14T15:00:16.962717Z"
    }
   },
   "id": "83eb7d2896a8d018",
   "execution_count": 141
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def compute_var(variance, n):\n",
    "    return np.sum(variance[n:])\n",
    "\n",
    "def compute_p(k, null_k):\n",
    "    return (np.sum(null_k < k) / len(null_k))\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-14T15:00:17.180301Z",
     "start_time": "2025-05-14T15:00:17.170276Z"
    }
   },
   "id": "4b51a1aeede5ecd4",
   "execution_count": 142
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "   model_id                                              w_rec  \\\n0  FcTeJvgU  [[0.022260262, 0.00653006, -0.010051201, 0.001...   \n\n                                                w_in  \\\n0  [[-0.033094015, 0.056794595], [-0.032934062, 0...   \n\n                                               w_out  \\\n0  [[0.021370161, 0.035784252, 0.16994824, -0.003...   \n\n                                                bias     mse_z  weight_decay  \\\n0  [0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.0...  0.040116         0.001   \n\n   threshold  sigma_rec  lambda_std  ...  lvar  dim  k  p_value  \\\n0      0.025        0.0         0.4  ...   1.0    2  2      0.0   \n\n                                             inertia  activity_std  \\\n0  [0.6784981109372814, 0.0002583028739083911, 0....      0.034947   \n\n                                        null_inertia  \\\n0  [[0.9982963013554711, 0.9946382707308987, 0.96...   \n\n                                            variance       var k_inertia  \n0  [0.70237833, 0.29743382, 0.00017074423, 9.9679... -8.579834  0.000258  \n\n[1 rows x 22 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>model_id</th>\n      <th>w_rec</th>\n      <th>w_in</th>\n      <th>w_out</th>\n      <th>bias</th>\n      <th>mse_z</th>\n      <th>weight_decay</th>\n      <th>threshold</th>\n      <th>sigma_rec</th>\n      <th>lambda_std</th>\n      <th>...</th>\n      <th>lvar</th>\n      <th>dim</th>\n      <th>k</th>\n      <th>p_value</th>\n      <th>inertia</th>\n      <th>activity_std</th>\n      <th>null_inertia</th>\n      <th>variance</th>\n      <th>var</th>\n      <th>k_inertia</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>FcTeJvgU</td>\n      <td>[[0.022260262, 0.00653006, -0.010051201, 0.001...</td>\n      <td>[[-0.033094015, 0.056794595], [-0.032934062, 0...</td>\n      <td>[[0.021370161, 0.035784252, 0.16994824, -0.003...</td>\n      <td>[0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.0...</td>\n      <td>0.040116</td>\n      <td>0.001</td>\n      <td>0.025</td>\n      <td>0.0</td>\n      <td>0.4</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>2</td>\n      <td>2</td>\n      <td>0.0</td>\n      <td>[0.6784981109372814, 0.0002583028739083911, 0....</td>\n      <td>0.034947</td>\n      <td>[[0.9982963013554711, 0.9946382707308987, 0.96...</td>\n      <td>[0.70237833, 0.29743382, 0.00017074423, 9.9679...</td>\n      <td>-8.579834</td>\n      <td>0.000258</td>\n    </tr>\n  </tbody>\n</table>\n<p>1 rows Ã— 22 columns</p>\n</div>"
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = original_df.copy()\n",
    "\n",
    "# Restrict to networks with dim and compute variance above dim\n",
    "dim = 2\n",
    "df = df[df.dim == dim]\n",
    "df = df[df.k >= dim]\n",
    "df['var'] = df.variance.apply(lambda x: compute_var(x, dim))\n",
    "df['k_inertia'] = df.inertia.apply(lambda x: x[dim - 1])\n",
    "df['var'] = np.log(df['var'])\n",
    "df.sort_values('var', ascending=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-14T15:03:02.989314Z",
     "start_time": "2025-05-14T15:03:02.942893Z"
    }
   },
   "id": "2449ebd25401ed83",
   "execution_count": 159
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "\n",
    "## Restrict connectivity to PCs\n",
    "model_data = df[df.model_id == 'FcTeJvgU']\n",
    "net = Net(n=100, input_size=2, dale=False)\n",
    "net.recurrent_layer.weight.data = torch.tensor(model_data['w_rec'].item())\n",
    "net.recurrent_layer.bias.data = torch.tensor(model_data['bias'].item())\n",
    "net.input_layer.weight.data = torch.tensor(model_data['w_in'].item())\n",
    "net.output_layer.weight.data = torch.tensor(model_data['w_out'].item())\n",
    "net.sigma_in = 0.\n",
    "net.sigma_rec = 0.\n",
    "u, z, mask, conditions = generate_trials(\n",
    "    n_trials=25)\n",
    "\n",
    "# COMPUTE RESPONSES\n",
    "x = net(u).detach().cpu().numpy()\n",
    "rows = []\n",
    "for k in range(u.shape[0]):\n",
    "    rows.append({'trial': k,\n",
    "                 'motion': conditions[k]['motion_coh'],\n",
    "                 'response': x[k, :, :]})\n",
    "df = pd.DataFrame(rows)\n",
    "df = df.groupby(['motion']).response.apply(lambda r: np.mean(np.stack(r), axis=0)).reset_index()\n",
    "#df = df.groupby('motion').response.apply(lambda r: np.mean(np.stack(r), axis=0)).reset_index()\n",
    "responses = np.stack(df.response.values)\n",
    "responses = responses.reshape(-1, responses.shape[2]).T\n",
    "#responses = responses[np.mean(responses, axis=1) >.025, ]\n",
    "responses = (responses - np.mean(responses, axis=1, keepdims=True)) / np.std(responses, axis=1, keepdims=True)\n",
    "responses = responses[~np.isnan(responses).any(axis=1)]\n",
    "\n",
    "## clustering\n",
    "\n",
    "\n",
    "w_rec = net.recurrent_layer.weight.data\n",
    "w_in = net.input_layer.weight.data\n",
    "w_out = net.output_layer.weight.data\n",
    "pca = PCA(n_components = 3).fit(responses.T)\n",
    "U = pca.components_\n",
    "A = w_rec@U.T\n",
    "b = net.recurrent_layer.bias.data.detach().cpu().numpy()\n",
    "\n",
    "A = np.concatenate((A, b[:, None]), axis=1)\n",
    "# Cluster hyperplanes\n",
    "k = 2\n",
    "clustering = KMeans(n_clusters=k, n_init=20).fit(A)\n",
    "\n",
    "# Compute magnitudes of each hyperplane\n",
    "magnitudes = np.linalg.norm(A, axis=1)\n",
    "\n",
    "# Construct Q of shape N x k\n",
    "q = torch.zeros((A.shape[0], k))\n",
    "for cluster in range(k):\n",
    "    for neuron in range(A.shape[0]):\n",
    "        if np.isin(neuron, np.argwhere(clustering.labels_==cluster)):\n",
    "            q[neuron, cluster] = torch.tensor(magnitudes[neuron]).float()\n",
    "q = q/torch.linalg.norm(q,dim=0)\n",
    "\n",
    "# Construct reduced model\n",
    "w_rec_reduced = q.t() @ w_rec @ q\n",
    "w_in_reduced = q.t() @ w_in\n",
    "w_out_reduced = w_out @ q\n",
    "\n",
    "# Initialize reduced model\n",
    "reduced_net = Net(n=k, input_size=2, dale=False)\n",
    "reduced_net.recurrent_layer.weight.data = w_rec_reduced\n",
    "reduced_net.recurrent_layer.bias.data = q.t()@torch.tensor(model_data['bias'].item())\n",
    "reduced_net.input_layer.weight.data = w_in_reduced\n",
    "reduced_net.output_layer.weight.data = w_out_reduced\n",
    "\n",
    "\n",
    "reduced_net.sigma_in = 0.\n",
    "reduced_net.sigma_rec = 0\n",
    "net.sigma_in = 0.\n",
    "net.sigma_rec = 0\n",
    "\n",
    "y = net(u).detach().cpu().numpy()\n",
    "y_pred =  (reduced_net(u) @ q.t()).detach().numpy()\n",
    "\n",
    "reduced_net.sigma_in = .03\n",
    "reduced_net.sigma_rec = 0\n",
    "net.sigma_in = .03\n",
    "net.sigma_rec = 0\n",
    "\n",
    "y_noise = net(u).detach().cpu().numpy()[:,25:,:]\n",
    "y_pred_noise =  (reduced_net(u) @ q.t()).detach().numpy()[:,25:,:]\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-14T15:03:04.024336Z",
     "start_time": "2025-05-14T15:03:03.359803Z"
    }
   },
   "id": "5be248cb826691c6",
   "execution_count": 160
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 150x150 with 1 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(1.5, 1.5))\n",
    "gs = gridspec.GridSpec(1, 1)\n",
    "ax = fig.add_subplot(gs[0, 0])\n",
    "\n",
    "#sns.scatterplot(data=new_df,x='z_1',y='z_2',hue='t',ax=ax,legend=False,s=1,alpha=.1,edgecolor=None)\n",
    "    \n",
    "\n",
    "sns.histplot(x = y_noise.flatten(),y = y_pred_noise.flatten(),ax=ax,legend=False,bins=50)\n",
    "#sns.histplot(x = y.flatten(),y = y_pred.flatten(),ax=ax,legend=False,color='k')\n",
    "\n",
    "# sns.scatterplot(data=new_df_mean[new_df_mean.t==74],x='z_1',y='z_2',ax=ax,legend=False,s=6,alpha=1,hue='theta',palette=palette)\n",
    "\n",
    "# Model predictions\n",
    "\n",
    "\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['top'].set_visible(False)\n",
    "\n",
    "ax.set_xlabel(\"PC 1\", fontsize=7)\n",
    "ax.set_ylabel(\"PC 2\", fontsize=7)\n",
    "#ax.set_title(r'$\\sum_{i\\geq 2}\\lambda_i = $'+str(np.round(variance,4)),fontsize=8)\n",
    "ax.xaxis.set_tick_params(labelsize=7, bottom=True)\n",
    "ax.yaxis.set_tick_params(labelsize=7, left=True)\n",
    "ax.spines['left'].set_color('black')\n",
    "ax.spines['bottom'].set_color('black')\n",
    "ax.axes.get_xaxis().set_visible(False)\n",
    "ax.axes.get_yaxis().set_visible(False)\n",
    "fig.savefig('Figures/Figure_reduced.jpg',\n",
    "            format='jpeg',\n",
    "            dpi=450,\n",
    "            bbox_inches='tight', transparent=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-14T15:04:46.868003Z",
     "start_time": "2025-05-14T15:04:46.185592Z"
    }
   },
   "id": "cedb8e4efc6bf723",
   "execution_count": 162
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "11a6d67f56f363b7"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
